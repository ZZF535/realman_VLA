import shutil
from pathlib import Path
import torch
import pandas as pd
from PIL import Image
from tqdm import tqdm

# å…¼å®¹å¯¼å…¥
try:
    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
except ImportError:
    from lerobot.datasets.lerobot_dataset import LeRobotDataset

# ================= ğŸ”§ é…ç½®åŒºåŸŸ (ä¿æŒä¸å˜) =================

RAW_DATA_ROOT = Path("/home/robot/data_896_test") 
TARGET_DATASET_DIR = Path("converted_dataset_final")
REPO_ID = "local/washing_machine_task" 
FPS = 30           
ROBOT_TYPE = "bi_realman" 

# ç›¸æœºæ˜ å°„
CAMERA_MAPPING = {
    "image_left": "observation.images.image_left_wrist",
    "image_right": "observation.images.image_right_wrist",
    "image_top": "observation.images.image_top"
}

# ä»»åŠ¡æè¿°
TASK_DESCRIPTION = "put clothes into washing machine"

# ==========================================================

def main():
    # å¦‚æœç›®æ ‡æ•°æ®é›†ç›®å½•å·²å­˜åœ¨ï¼Œæ¸…ç†æ—§ç›®å½•
    if TARGET_DATASET_DIR.exists():
        print(f"âš ï¸  æ­£åœ¨æ¸…ç†æ—§ç›®å½• {TARGET_DATASET_DIR} ...")
        shutil.rmtree(TARGET_DATASET_DIR)

    # æ‰«ææ‰€æœ‰ episode æ–‡ä»¶å¤¹
    episode_folders = sorted([p for p in RAW_DATA_ROOT.glob("put_clothes_*") if p.is_dir()])
    print(f"ğŸ‘€ æ‰«æåˆ° {len(episode_folders)} ä¸ª Episode")

    if not episode_folders:
        print(f"âŒ é”™è¯¯: æ²¡æ‰¾åˆ°æ–‡ä»¶å¤¹")
        return

    # --- 1. è‡ªåŠ¨æ¢æµ‹ç»´åº¦ ---
    first_parquet = episode_folders[0] / "data" / "chunk-000" / "episode_000000.parquet"
    if not first_parquet.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {first_parquet}")
        return

    print(f"ğŸ“– è¯»å–ç¤ºä¾‹ä»¥æ£€æµ‹ç»´åº¦...")
    df_sample = pd.read_parquet(first_parquet)
    
    # è‡ªåŠ¨æ£€æµ‹ Action ç»´åº¦
    if 'action' in df_sample.columns:
        action_dim = len(df_sample['action'].iloc[0])
    else:
        action_cols = [c for c in df_sample.columns if "action" in c]
        action_dim = len(action_cols)

    # è‡ªåŠ¨æ£€æµ‹ State ç»´åº¦
    if 'observation.state' in df_sample.columns:
        state_dim = len(df_sample['observation.state'].iloc[0])
    else:
        state_cols = [c for c in df_sample.columns if "state" in c or "qpos" in c]
        state_dim = len(state_cols)

    print(f"âœ… ç»´åº¦ç¡®è®¤: Action={action_dim}, State={state_dim}")

    # --- 2. å®šä¹‰ Features ---
    features = {
        "action": {
            "dtype": "float32",
            "shape": (action_dim,),
            "names": [f"motor_{i}" for i in range(action_dim)]
        },
        "observation.state": {
            "dtype": "float32",
            "shape": (state_dim,),
            "names": [f"motor_{i}" for i in range(state_dim)]
        },
        # âš ï¸ [ä¿®å¤ç‚¹1] ä½ çš„ç‰ˆæœ¬è¦æ±‚è¿™é‡Œçš„ key å¿…é¡»å« 'task'ï¼Œè€Œä¸æ˜¯ 'task_index'
        "task": {
            "dtype": "int64",
            "shape": (1,),
            "names": ["index"]
        }
    }
    
    # ä¸ºæ¯ä¸ªç›¸æœºæ·»åŠ å›¾åƒç‰¹å¾
    for cam_key in CAMERA_MAPPING.keys():
        features[f"observation.images.{cam_key}"] = {
            "dtype": "video",
            "shape": (480, 640, 3), 
            "names": ["height", "width", "channel"]
        }

    # --- 3. åˆå§‹åŒ–æ•°æ®é›† ---
    print("ğŸš€ åˆå§‹åŒ– LeRobot æ•°æ®é›†...")
    dataset = LeRobotDataset.create(
        repo_id=REPO_ID,
        fps=FPS,
        root=TARGET_DATASET_DIR,
        robot_type=ROBOT_TYPE,
        features=features,
        use_videos=True,
    )

    # --- 4. è½¬æ¢å¾ªç¯ ---
    for ep_folder in tqdm(episode_folders, desc="Converting"):
        try:
            # è¯»å– Parquet æ–‡ä»¶
            parquet_path = ep_folder / "data" / "chunk-000" / "episode_000000.parquet"
            df = pd.read_parquet(parquet_path)
            num_frames = len(df)
            
            for i in range(num_frames):
                # æå– Action
                if 'action' in df.columns:
                    action = torch.tensor(df.iloc[i]['action'])
                else:
                    act_cols = sorted([c for c in df.columns if "action" in c])
                    action = torch.tensor(df.iloc[i][act_cols].values, dtype=torch.float32)

                # æå– State
                if 'observation.state' in df.columns:
                    state = torch.tensor(df.iloc[i]['observation.state'])
                else:
                    state_cols = sorted([c for c in df.columns if "state" in c or "qpos" in c])
                    if state_cols:
                        state = torch.tensor(df.iloc[i][state_cols].values, dtype=torch.float32)
                    else:
                        state = torch.zeros(state_dim)

                # å‡†å¤‡å¸§æ•°æ®
                frame_data = {
                    "action": action,
                    "observation.state": state,
                    "task": torch.tensor(0, dtype=torch.int64)  # ä¸ºæ¯å¸§æ·»åŠ  task ç‰¹å¾
                }

                # è¯»å–å›¾åƒå¹¶æ·»åŠ åˆ°å¸§æ•°æ®
                for cam_key, folder_name in CAMERA_MAPPING.items():
                    img_dir = ep_folder / "images" / folder_name / "episode_000000"
                    
                    # ä¼˜å…ˆæ‰¾ frame_000000.jpg
                    img_path = img_dir / f"frame_{i:06d}.jpg"
                    if not img_path.exists():
                        img_path = img_dir / f"{i}.jpg"
                    
                    if not img_path.exists():
                        raise FileNotFoundError(f"Missing image: {img_path}")

                    frame_data[f"observation.images.{cam_key}"] = Image.open(img_path)

                dataset.add_frame(frame_data)

            # ä¿å­˜ Episode
            dataset.save_episode(task=TASK_DESCRIPTION)

        except Exception as e:
            print(f"\nâŒ Error in {ep_folder.name}: {e}")
            dataset.clear_episode_buffer()
            continue

    # --- 5. æ”¶å°¾ ---
    print("\nğŸ“¦ Finalizing Dataset...")
    
    # å°è¯•è°ƒç”¨ consolidateï¼Œå¦‚æœç‰ˆæœ¬ä¸æ”¯æŒåˆ™è·³è¿‡
    try:
        dataset.consolidate()
        print("âœ… Metadata consolidated successfully.")
    except AttributeError:
        print("âš ï¸  Skip: 'consolidate' method not found (OK for older versions).")
        print("    æ•°æ®å·²ä¿å­˜å®Œæˆã€‚å¦‚æœéœ€è¦ç»Ÿè®¡ä¿¡æ¯ï¼Œè¯·å°è¯•è¿è¡Œ lerobot è‡ªå¸¦çš„ compute_stats è„šæœ¬ã€‚")
    except Exception as e:
        print(f"âš ï¸  Consolidation warning: {e}")
    
    print("="*50)
    print(f"ğŸ‰ è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“‚ æ–°æ•°æ®é›†ä½ç½®: {TARGET_DATASET_DIR}/{REPO_ID}")
    print("="*50)

if __name__ == "__main__":
    main()
