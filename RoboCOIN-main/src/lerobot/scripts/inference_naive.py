import draccus
import imageio
import numpy as np
import os
import threading
import time
import torch
import traceback
from dataclasses import dataclass, field
from sshkeyboard import listen_keyboard, stop_listening
from typing import List

from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.policies.factory import make_policy
from lerobot.robots.utils import make_robot_from_config
from lerobot.scripts.server.helpers import (
    map_robot_keys_to_lerobot_features,
    raw_observation_to_observation,
)
from lerobot.policies.pretrained import PreTrainedConfig
from lerobot.cameras.dummy.configuration_dummy import DummyCameraConfig
from lerobot.cameras.realsense.configuration_realsense import RealSenseCameraConfig
from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig
from lerobot.robots.config import RobotConfig
from lerobot.robots.utils import make_robot_from_config
from lerobot.robots import (
    dummy,
    bi_dummy,
    piper,
    bi_piper,
    realman,
    bi_realman,
)


@dataclass
class LocalRobotClientConfig:
    robot: RobotConfig
    task: str = "place the bowl on the plate"
    pretrained_path: str = ""
    device: str = "cuda:0"
    repo_id: str = "piper/place_the_bowl_on_the_plate_filtered"
    result_dir: str = "results/"
    frequency: int = 30
    camera_keys: List[str] = field(default_factory=lambda: [
        'front'
    ])
    

class VideoRecorder:
    def __init__(
        self,
        save_dir,
        fps: int = 30,
    ):
        self.save_dir = save_dir
        self.fps = fps
        self._frames = []

        os.makedirs(self.save_dir, exist_ok=True)

    def add(self, frame):
        if isinstance(frame, list):
            # [(H, W, C), ...] -> (H, W * N, C)
            frame = np.concatenate(frame, axis=1)
        self._frames.append(frame)
    
    def save(self, task, success):
        save_path = os.path.join(self.save_dir, f"{task.replace('.', '')}_{'success' if success else 'failed'}_{time.strftime('%Y%m%d_%H%M%S')}.mp4")
        print(f'Saving video to {save_path}...')
        imageio.mimwrite(save_path, self._frames, fps=self.fps)
        self._frames = []


class KeyboardListener:
    def __init__(self):
        self._listener = threading.Thread(target=listen_keyboard, args=(self._on_press,))
        self._listener.daemon = True

        self._quit = False
        self._success = None
    
    def listen(self):
        self._listener.start()
    
    def reset(self):
        self._quit = False
        self._success = None
    
    def _on_press(self, key):
        if key == 'q':
            self._quit = True
        
        elif key == 'y':
            self._success = True
            stop_listening()
        
        elif key == 'n':
            self._success = False
            stop_listening()


class LocalRobotClient:
#    def __init__(self, config: LocalRobotClientConfig):
#       self.config = config
#
 #       self.video_recorder = VideoRecorder(config.result_dir, fps=config.frequency)
  #      self.keyboard_listener = KeyboardListener()
#
 #       # self.dataset = LeRobotDataset(repo_id=config.repo_id)
  #      from lerobot.policies.factory import get_policy_class
   #     
    #    print(f"ðŸš€ ç›´æŽ¥åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹: {config.pretrained_path}")
     #   
      #  # 1. èŽ·å–ç­–ç•¥ç±» (å¦‚ ACTPolicy)
       # policy_cls = get_policy_class(policy_config.type)
        
        ## 2. ç›´æŽ¥ä»Žè·¯å¾„åŠ è½½ (è‡ªåŠ¨è¯»å– config.json å’Œ model.safetensors)
       # self.policy = policy_cls.from_pretrained(config.pretrained_path)
        
        ## 3. ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è®¾ä¸ºè¯„ä¼°æ¨¡å¼
       # self.policy.to(policy_config.device)
        #self.policy.eval()
        
       # print("âœ… ç­–ç•¥åŠ è½½æˆåŠŸï¼(è·³è¿‡äº†æ•°æ®é›†å…ƒæ•°æ®æ£€æŸ¥)")
        #policy_config = PreTrainedConfig.from_pretrained(self.config.pretrained_path)
        #policy_config.pretrained_path = self.config.pretrained_path
       # self.policy = make_policy(policy_config, ds_meta=self.dataset.meta)
        #self.policy.to(config.device)
#
 #       self.robot = make_robot_from_config(config.robot)
#
 #       self._is_finished = False
    def __init__(self, config: LocalRobotClientConfig):
        self.config = config
        self.video_recorder = VideoRecorder(config.result_dir, fps=config.frequency)
        self.keyboard_listener = KeyboardListener()

        # =========================================================
        # âš¡ï¸ ç»ˆæžä¿®å¤ V4ï¼šæ™ºèƒ½é”®åæ˜ å°„ + å¼ºåˆ¶ CPU
        # =========================================================
        from lerobot.configs.policies import PreTrainedConfig
        from lerobot.policies.factory import get_policy_class
        import safetensors.torch
        import torch
        from pathlib import Path

        print(f"ðŸš€ å‡†å¤‡åŠ è½½æ¨¡åž‹: {config.pretrained_path}")
        model_dir = Path(config.pretrained_path)
        
        # 1. åŠ è½½é…ç½®
        policy_config = PreTrainedConfig.from_pretrained(config.pretrained_path)
        policy_config.pretrained_path = config.pretrained_path
        
        # 2. åˆå§‹åŒ–ç­–ç•¥
        print(f"â„¹ï¸ ç­–ç•¥ç±»åž‹: {policy_config.type}")
        policy_cls = get_policy_class(policy_config.type)
        self.policy = policy_cls.from_pretrained(config.pretrained_path)
        
        # --- ðŸ”§ è¾…åŠ©å‡½æ•°ï¼šé”®åé‡æ˜ å°„ ---
        def remap_keys(state_dict, module_prefix):
            new_sd = {}
            for k, v in state_dict.items():
                # è§£æžåŽç¼€ (mean/std/min/max)
                if k.endswith(".mean"): stat, suffix_len = "mean", 5
                elif k.endswith(".std"): stat, suffix_len = "std", 4
                elif k.endswith(".min"): stat, suffix_len = "min", 4
                elif k.endswith(".max"): stat, suffix_len = "max", 4
                else: continue
                
                # èŽ·å–ç‰¹å¾å (åŽ»é™¤åŽç¼€)
                feature_name = k[:-suffix_len] # e.g. "observation.images.image_top"
                
                # è½¬æ¢æ ¼å¼: ç‚¹ -> ä¸‹åˆ’çº¿, å¢žåŠ  buffer_ å‰ç¼€
                feature_slug = feature_name.replace(".", "_")
                new_key = f"{module_prefix}.buffer_{feature_slug}.{stat}"
                
                print(f"   æ˜ å°„: {k} -> {new_key}")
                new_sd[new_key] = v
            return new_sd
        # -----------------------------------

        # 3. åŠ è½½å¹¶æ‰“è¡¥ä¸
        print("ðŸ”§ æ­£åœ¨æ™ºèƒ½ä¿®å¤ç»Ÿè®¡æ•°æ®...")
        
        # (A) è¾“å…¥ç»Ÿè®¡ -> normalize_inputs
        pre_files = list(model_dir.glob("policy_preprocessor_step_*_normalizer_processor.safetensors"))
        if pre_files:
            print(f"   -> åŠ è½½è¾“å…¥ç»Ÿè®¡: {pre_files[0].name}")
            pre_sd = safetensors.torch.load_file(pre_files[0])
            patch_sd = remap_keys(pre_sd, "normalize_inputs")
            self.policy.load_state_dict(patch_sd, strict=False)
        
        # (B) è¾“å‡ºç»Ÿè®¡ -> unnormalize_outputs
        post_files = list(model_dir.glob("policy_postprocessor_step_*_unnormalizer_processor.safetensors"))
        if post_files:
            print(f"   -> åŠ è½½è¾“å‡ºç»Ÿè®¡: {post_files[0].name}")
            post_sd = safetensors.torch.load_file(post_files[0])
            patch_sd = remap_keys(post_sd, "unnormalize_outputs")
            self.policy.load_state_dict(patch_sd, strict=False)

        # 4. å¼ºåˆ¶ CPU (RTX 5080 å…¼å®¹)
        print("âš ï¸ å¼ºåˆ¶åˆ‡æ¢è‡³ CPU æ¨¡å¼...")
        self.policy.to("cpu")
        self.policy.eval()
        
        print("âœ… ç­–ç•¥åŠ è½½å®Œæ¯•ï¼")
        # =========================================================

        self.robot = make_robot_from_config(config.robot)
        self._is_finished = False
    
    
    
    
    def start(self):
        self.keyboard_listener.listen()
        self.robot.connect()
        time.sleep(5)
    
    def control_loop(self):
        # while not self._is_finished:
        #     obs = self._prepare_observation(self.robot.get_observation())
        #     with torch.inference_mode():
        #         action = self.policy.select_action(obs)[0]
        #     obs = self.robot.get_observation()
        #     state = None
        #     action = self._prepare_action(action, state)
        #   print('Prepared action:', action)
        self.robot.visualizer = None
        
        while not self._is_finished:
            start_time = time.perf_counter()
            
            # 1. èŽ·å–è§‚æµ‹
            obs = self._prepare_observation(self.robot.get_observation())
            
            # 2. æ¨¡åž‹æŽ¨ç† -> å¾—åˆ° 26ç»´ Tensor
            action = self.policy.select_action(obs)[0]
            
            # 3. ðŸ”¥ æ ¸å¿ƒä¿®å¤: Tensor è½¬ Dictionary
            # BiBaseRobot éœ€è¦å­—å…¸æ‰èƒ½åˆ†å‘å·¦å³è‡‚åŠ¨ä½œ
            # æˆ‘ä»¬æ ¹æ®ä¹‹å‰çš„åˆ†æžï¼šå·¦è‡‚æ˜¯å‰7ä¸ªï¼Œå³è‡‚æ˜¯ç¬¬13-20ä¸ª (è·³è¿‡ä¸­é—´çš„ä½å§¿)
            
            # è½¬ä¸º CPU numpy æ•°ç»„æ–¹ä¾¿å¤„ç†
            act_np = action.to("cpu").numpy()
            
            action_dict = {}
            
            # --- å·¦è‡‚ (Index 0-6) ---
            # æˆ‘ä»¬ç›´æŽ¥åŽ»è¯» robot.left_robot.motor_names æˆ–è€… _motors_ft.keys()
            # è¿™æ ·ç»å¯¹ä¸ä¼šé”™ï¼
            try:
                # å°è¯•èŽ·å–ç”µæœºæ˜ å°„é”®å
                left_motor_keys = list(self.robot.left_robot._motors_ft.keys())
                right_motor_keys = list(self.robot.right_robot._motors_ft.keys())
            except AttributeError:
                # å¦‚æžœæ˜¯æ—§ç‰ˆä»£ç æ²¡æœ‰ _motors_ftï¼Œå›žé€€åˆ° joint_names
                left_motor_keys = self.robot.left_robot.config.joint_names
                right_motor_keys = self.robot.right_robot.config.joint_names

            # å¡«å……å·¦è‡‚æ•°æ®
            for i, key_name in enumerate(left_motor_keys):
                # å¦‚æžœ key_name å·²ç»æ˜¯ "joint_1_pos"ï¼Œé‚£åŠ ä¸Š "left_" å°±æ˜¯ "left_joint_1_pos"
                # è¿™æ­£æ˜¯ BiBaseRobot å‰¥ç¦»å‰ç¼€åŽæƒ³è¦çš„åå­—
                action_dict[f"left_{key_name}"] = act_np[i]
                
            # å¡«å……å³è‡‚æ•°æ® (ä»Ž index 13 å¼€å§‹)
            for i, key_name in enumerate(right_motor_keys):
                action_dict[f"right_{key_name}"] = act_np[13 + i]
            
            # 4. å‘é€å­—å…¸ç»™æœºå™¨äºº
            # æ­¤æ—¶ action_dict æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰å…³èŠ‚æ•°æ®çš„å­—å…¸ï¼ŒBiBaseRobot èƒ½è¯»æ‡‚
            self.robot.send_action(action_dict)
            # self.robot.send_action(action)
            self._after_action()
            time.sleep(1 / self.config.frequency)

    def stop(self):
        self.robot.disconnect()
    
    # def _prepare_observation(self, observation):
    #     observation['task'] = self.config.task
    #     observation = raw_observation_to_observation(
    #         observation, 
    #         map_robot_keys_to_lerobot_features(self.robot),
    #         self.policy.config.image_features,
    #         device=self.config.device,
    #     )
        
    #     import torch
    #     state = observation["observation.state"]
        
    #     # æ£€æŸ¥æ˜¯å¦æ˜¯ 14 ç»´ (2è‡‚ * 7å…³èŠ‚)
    #     if state.shape[-1] == 14:
    #         print("âš ï¸ æ£€æµ‹åˆ°çŠ¶æ€ç»´åº¦ä¸º 14ï¼Œæ­£åœ¨è‡ªåŠ¨è¡¥é½ 12 ç»´é€Ÿåº¦æ•°æ®...")
    #         batch_size = state.shape[0] if state.dim() > 1 else 1
    #         device = state.device
    #         dtype = state.dtype
            
    #         # æž„é€  12 ä¸ª 0 (å‡è®¾ä¸¤è‡‚å„ 6 ä¸ªé€Ÿåº¦)
    #         zeros = torch.zeros((12,), device=device, dtype=dtype)
    #         if state.dim() > 1:
    #             zeros = zeros.unsqueeze(0).repeat(batch_size, 1)
                
    #         # è¿™é‡Œçš„æ‹¼æŽ¥é¡ºåºå¾ˆé‡è¦ï¼é€šå¸¸ ACT æ˜¯ [left_pos, left_vel, right_pos, right_vel]
    #         # çŽ°åœ¨çš„ 14 ç»´æ˜¯ [left_pos, right_pos] (å‡è®¾é¡ºåº)
    #         # æˆ‘ä»¬éœ€è¦æŠŠå®ƒæ‹†å¼€ï¼Œåˆ†åˆ«æ’è¿›åŽ»
            
    #         left_pos = state[..., :7]  # å‰7ä¸ª
    #         right_pos = state[..., 7:] # åŽ7ä¸ª
            
    #         left_vel = torch.zeros((6,), device=device, dtype=dtype)
    #         right_vel = torch.zeros((6,), device=device, dtype=dtype)
            
    #         if state.dim() > 1:
    #             left_vel = left_vel.unsqueeze(0).repeat(batch_size, 1)
    #             right_vel = right_vel.unsqueeze(0).repeat(batch_size, 1)
            
    #         # æ‹¼æˆ [lp, lv, rp, rv] = 7+6+7+6 = 26
    #         new_state = torch.cat([left_pos, left_vel, right_pos, right_vel], dim=-1)
            
    #         observation["observation.state"] = new_state
            
    #     return observation
        # return observation
        
        
    # def _prepare_observation(self, robot_obs):
    #     from lerobot.scripts.server.helpers import raw_observation_to_observation
        
    #     # 1. æ··åˆå¯¹è±¡ (HybridFeature) - è§£å†³é…ç½®å…¼å®¹æ€§
    #     class HybridFeature(dict):
    #         def __getattr__(self, name):
    #             if name in self: return self[name]
    #             raise AttributeError(f"No attribute {name}")

    #     input_features_hybrid = {}
        
    #     for key, feature in self.policy.config.input_features.items():
    #         h_feat = HybridFeature()
    #         # å¤åˆ¶æ•°æ®
    #         if isinstance(feature, dict):
    #             h_feat.update(feature)
    #         else:
    #             for attr in ["type", "dtype", "shape", "names"]:
    #                 if hasattr(feature, attr):
    #                     val = getattr(feature, attr)
    #                     if val is not None: h_feat[attr] = val
                            
    #         # è¡¥å…¨ dtype
    #         if "dtype" not in h_feat:
    #             f_type = h_feat.get("type", getattr(feature, "type", None))
    #             h_feat["dtype"] = "video" if (f_type == "image" or "image" in key) else "float32"
            
    #         # è¡¥å…¨ names (é‡è¦ï¼šè¿™é‡Œæˆ‘ä»¬åªè¯·æ±‚æœºå™¨äººèƒ½æä¾›çš„ 14 ä¸ªæ•°æ®)
    #         if key == "observation.state" and "names" not in h_feat:
    #             try:
    #                 left_names = [f"left_{n}_pos" for n in self.robot.left_robot.config.joint_names]
    #                 right_names = [f"right_{n}_pos" for n in self.robot.right_robot.config.joint_names]
    #                 h_feat["names"] = left_names + right_names
    #             except AttributeError:
    #                 base_names = [f"joint_{i+1}_pos" for i in range(6)] + ["gripper_pos"]
    #                 h_feat["names"] = [f"left_{n}" for n in base_names] + [f"right_{n}" for n in base_names]

    #         input_features_hybrid[key] = h_feat

    #     # 2. ç”Ÿæˆåˆæ­¥è§‚æµ‹å€¼ (æ­¤æ—¶ state æ˜¯ 14 ç»´)
    #     observation = raw_observation_to_observation(
    #         robot_obs,
    #         input_features_hybrid,
    #         input_features_hybrid,
    #         "cpu" 
    #     )
        
    #     observation['task'] = self.config.task
        
    #     # 3. å¼ºåˆ¶ CPU
    #     for key in observation:
    #         if hasattr(observation[key], "to"):
    #             observation[key] = observation[key].to("cpu")
        
    #     import torch
    #     state = observation["observation.state"]
        
    #     # =========================================================
    #     # âš¡ï¸ æ ¸å¿ƒä¿®å¤ï¼šç»´åº¦è¡¥é½ (14 -> 26) 
    #     # =========================================================
    #     if state.shape[-1] == 14:
    #         # print("âš ï¸ æ£€æµ‹åˆ° 14 ç»´æ•°æ®ï¼Œæ­£åœ¨è‡ªåŠ¨è¡¥é½ä½å§¿æ•°æ®(0)...")
    #         batch_size = state.shape[0] if state.dim() > 1 else 1
    #         device = "cpu"
    #         dtype = state.dtype
            
    #         # åˆ‡åˆ†å·¦å³è‡‚æ•°æ® (å„7ç»´: 6å…³èŠ‚ + 1å¤¹çˆª)
    #         # å‡è®¾é¡ºåºæ˜¯ [Left_Joints(6), Left_Gripper(1), Right_Joints(6), Right_Gripper(1)]
    #         left_part = state[..., :7]
    #         right_part = state[..., 7:]
            
    #         # åˆ›å»º 6 ç»´é›¶å‘é‡ (ä»£è¡¨ç¼ºå¤±çš„ä½å§¿)
    #         zeros = torch.zeros((6,), device=device, dtype=dtype)
    #         if state.dim() > 1:
    #             zeros = zeros.unsqueeze(0).repeat(batch_size, 1)
            
    #         # é‡æ–°æ‹¼æŽ¥ä¸º 26 ç»´: [L(7), L_Pose(0), R(7), R_Pose(0)]
    #         new_state = torch.cat([left_part, zeros, right_part, zeros], dim=-1)
            
    #         observation["observation.state"] = new_state
            
    #     return observation
    
    def _prepare_observation(self, robot_obs):
        from lerobot.scripts.server.helpers import raw_observation_to_observation
        import torch
        
        # 1. æ··åˆå¯¹è±¡ (HybridFeature) - å…¼å®¹æ€§å¿…é¡»å“
        class HybridFeature(dict):
            def __getattr__(self, name):
                if name in self: return self[name]
                raise AttributeError(f"No attribute {name}")

        input_features_hybrid = {}
        
        # éåŽ†æ¨¡åž‹éœ€è¦çš„æ‰€æœ‰è¾“å…¥ç‰¹å¾
        for key, feature in self.policy.config.input_features.items():
            h_feat = HybridFeature()
            if isinstance(feature, dict):
                h_feat.update(feature)
            else:
                for attr in ["type", "dtype", "shape", "names"]:
                    if hasattr(feature, attr):
                        val = getattr(feature, attr)
                        if val is not None: h_feat[attr] = val
                            
            if "dtype" not in h_feat:
                f_type = h_feat.get("type", getattr(feature, "type", None))
                h_feat["dtype"] = "video" if (f_type == "image" or "image" in key) else "float32"
            
            # è¡¥å…¨ names
            if key == "observation.state" and "names" not in h_feat:
                try:
                    left_names = [f"left_{n}_pos" for n in self.robot.left_robot.config.joint_names]
                    right_names = [f"right_{n}_pos" for n in self.robot.right_robot.config.joint_names]
                    h_feat["names"] = left_names + right_names
                except AttributeError:
                    base_names = [f"joint_{i+1}_pos" for i in range(6)] + ["gripper_pos"]
                    h_feat["names"] = [f"left_{n}" for n in base_names] + [f"right_{n}" for n in base_names]

            input_features_hybrid[key] = h_feat

            # =========================================================
            # ðŸ”¥ðŸ”¥ è¶…çº§è¡¥ä¸: è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±/ä¸¢å¸§çš„å›¾åƒ ðŸ”¥ðŸ”¥
            # =========================================================
            if h_feat["dtype"] == "video":
                # è®¡ç®— robot_obs åº”è¯¥æœ‰çš„é”®å
                # utils.py çš„é€»è¾‘æ˜¯: key.removeprefix("observation.images.")
                # æˆ‘ä»¬æ¨¡æ‹Ÿè¿™ä¸ªé€»è¾‘ï¼Œç¡®ä¿é”®å 100% åŒ¹é…
                target_key = key.replace("observation.images.", "")
                
                # å¦‚æžœè¿™ä¸ªå›¾å› ä¸ºä¸¢å¸§/æœªè¿žæŽ¥è€Œç¼ºå¤±
                if target_key not in robot_obs:
                    # print(f"âš ï¸ è­¦å‘Š: å›¾åƒ {target_key} ä¸¢å¸§æˆ–ç¼ºå¤±ï¼Œè‡ªåŠ¨è¡¥å…¨é»‘å¸§...")
                    shape = h_feat.get("shape", (3, 480, 640))
                    # è¡¥ä¸€ä¸ªå…¨ 0 çš„ Tensor
                    robot_obs[target_key] = torch.zeros(shape, dtype=torch.float32)

        # 2. ç”Ÿæˆåˆæ­¥è§‚æµ‹å€¼
        observation = raw_observation_to_observation(
            robot_obs,
            input_features_hybrid,
            input_features_hybrid,
            "cpu" 
        )
        
        observation['task'] = self.config.task
        
        # 3. å¼ºåˆ¶ CPU
        for key in observation:
            if hasattr(observation[key], "to"):
                observation[key] = observation[key].to("cpu")
        
        # 4. ç»´åº¦è¡¥é½ (14 -> 26)
        state = observation["observation.state"]
        if state.shape[-1] == 14:
            batch_size = state.shape[0] if state.dim() > 1 else 1
            device = "cpu"
            dtype = state.dtype
            
            left_pos = state[..., :7]
            right_pos = state[..., 7:]
            
            zeros = torch.zeros((6,), device=device, dtype=dtype)
            if state.dim() > 1:
                zeros = zeros.unsqueeze(0).repeat(batch_size, 1)
            
            new_state = torch.cat([left_pos, zeros, right_pos, zeros], dim=-1)
            observation["observation.state"] = new_state
            
        return observation
    
    def _prepare_action(self, action, state):
        return {k: action[i].item() for i, k in enumerate(self.robot.action_features.keys())}

    def _after_action(self):
        obs = self.robot.get_observation()
        frames = [obs[key] for key in self.config.camera_keys]
        self.video_recorder.add(frames)

        if self.keyboard_listener._quit:
            print('Success? (y/n): ', end='', flush=True)
            while self.keyboard_listener._success is None:
                time.sleep(0.1)
            print('Got:', self.keyboard_listener._success)
            self.video_recorder.save(task=self.config.task, success=self.keyboard_listener._success)
            self._is_finished = True


@draccus.wrap()
def main(cfg: LocalRobotClientConfig):
    client = LocalRobotClient(cfg)
    client.start()

    try:
        client.control_loop()
    except KeyboardInterrupt:
        client.stop()
    except Exception as e:
        traceback.print_exc()
    finally:
        client.stop()


if __name__ == "__main__":
    main()
